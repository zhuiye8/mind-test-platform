import React, { useState, useRef, useEffect, useCallback } from 'react';
import {
  Card,
  Button,
  Space,
  Typography,
  Tag,
  Alert,
  Progress,
  Switch,
  Tooltip,
  Avatar,
} from 'antd';
import {
  VideoCameraOutlined,
  DisconnectOutlined,
  LinkOutlined,
  EyeOutlined,
  WarningOutlined,
  CheckCircleOutlined,
  AudioOutlined,
} from '@ant-design/icons';

const { Text } = Typography;

interface EmotionAnalyzerProps {
  examId: string;
  studentId: string;
  onEmotionData?: (data: EmotionData) => void;
  onAnalysisComplete?: (analysisId: string) => void;
  onTimelineEvent?: (event: string, timestamp: number, metadata?: any) => void;
  disabled?: boolean;
  audioOnly?: boolean; // æ–°å¢ï¼šä»…éº¦å…‹é£æ¨¡å¼
}

interface EmotionData {
  timestamp: number;
  emotions: {
    happiness: number;
    sadness: number;
    anger: number;
    fear: number;
    surprise: number;
    disgust: number;
  };
  engagement: number;
  stress: number;
}

interface WebSocketStatus {
  connected: boolean;
  connecting: boolean;
  error: string | null;
  reconnectAttempts: number;
}

const EmotionAnalyzer: React.FC<EmotionAnalyzerProps> = ({
  examId,
  studentId,
  onEmotionData,
  onAnalysisComplete,
  onTimelineEvent,
  disabled = false,
  audioOnly = false,
}) => {
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [wsStatus, setWsStatus] = useState<WebSocketStatus>({
    connected: false,
    connecting: false,
    error: null,
    reconnectAttempts: 0,
  });
  const [emotionData, setEmotionData] = useState<EmotionData | null>(null);
  const [analysisEnabled, setAnalysisEnabled] = useState(true);
  const [videoStream, setVideoStream] = useState<MediaStream | null>(null);
  const [audioStream, setAudioStream] = useState<MediaStream | null>(null);
  const [framesSent, setFramesSent] = useState(0);
  const [audioLevel, setAudioLevel] = useState(0); // éŸ³é¢‘éŸ³é‡çº§åˆ«

  const wsRef = useRef<WebSocket | null>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const intervalRef = useRef<NodeJS.Timeout | null>(null);
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const analysisSessionId = useRef<string>('');

  // æ¸…ç†èµ„æº
  const cleanup = useCallback(() => {
    if (intervalRef.current) {
      clearInterval(intervalRef.current);
      intervalRef.current = null;
    }
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current);
      reconnectTimeoutRef.current = null;
    }
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
    if (videoStream) {
      videoStream.getTracks().forEach(track => track.stop());
      setVideoStream(null);
    }
    if (audioStream) {
      audioStream.getTracks().forEach(track => track.stop());
      setAudioStream(null);
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    analyserRef.current = null;
    setAudioLevel(0);
  }, [videoStream, audioStream]);

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return cleanup;
  }, [cleanup]);

  // åˆå§‹åŒ–WebSocketè¿æ¥
  const initWebSocket = useCallback(async () => {
    if (wsRef.current || !analysisEnabled || disabled) return;

    setWsStatus(prev => ({ ...prev, connecting: true, error: null }));

    try {
      // è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„æƒ…ç»ªåˆ†æAPIåœ°å€
      // ç¤ºä¾‹: wss://emotion-api.example.com/ws
      const wsUrl = `wss://localhost:3001/api/emotion/stream?examId=${examId}&studentId=${studentId}&audioOnly=${audioOnly}`;
      
      wsRef.current = new WebSocket(wsUrl);

      wsRef.current.onopen = () => {
        console.log('æƒ…ç»ªåˆ†æWebSocketè¿æ¥æˆåŠŸ');
        setWsStatus({
          connected: true,
          connecting: false,
          error: null,
          reconnectAttempts: 0,
        });
        onTimelineEvent?.('emotion_analysis_connected', Date.now());

        // å‘é€åˆå§‹åŒ–æ¶ˆæ¯
        if (wsRef.current) {
          wsRef.current.send(JSON.stringify({
            type: 'init',
            examId,
            studentId,
            audioOnly,
            timestamp: Date.now(),
          }));
        }
      };

      wsRef.current.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          
          if (data.type === 'emotion_data') {
            const emotionData: EmotionData = data.payload;
            setEmotionData(emotionData);
            onEmotionData?.(emotionData);
            onTimelineEvent?.('emotion_data_received', Date.now(), emotionData);
          } else if (data.type === 'analysis_complete') {
            analysisSessionId.current = data.analysisId;
            onAnalysisComplete?.(data.analysisId);
            onTimelineEvent?.('emotion_analysis_complete', Date.now(), { analysisId: data.analysisId });
          } else if (data.type === 'error') {
            console.error('æƒ…ç»ªåˆ†æé”™è¯¯:', data.message);
            setWsStatus(prev => ({ ...prev, error: data.message }));
          }
        } catch (err) {
          console.error('è§£æWebSocketæ¶ˆæ¯å¤±è´¥:', err);
        }
      };

      wsRef.current.onclose = (event) => {
        console.log('æƒ…ç»ªåˆ†æWebSocketè¿æ¥å…³é—­:', event.code, event.reason);
        setWsStatus(prev => ({ 
          ...prev, 
          connected: false, 
          connecting: false,
          error: event.code !== 1000 ? `è¿æ¥å…³é—­: ${event.reason || event.code}` : null
        }));
        
        // å¦‚æœä¸æ˜¯æ­£å¸¸å…³é—­ä¸”æ­£åœ¨åˆ†æï¼Œå°è¯•é‡è¿
        if (event.code !== 1000 && isAnalyzing && wsStatus.reconnectAttempts < 3) {
          scheduleReconnect();
        }
      };

      wsRef.current.onerror = (error) => {
        console.error('æƒ…ç»ªåˆ†æWebSocketé”™è¯¯:', error);
        setWsStatus(prev => ({ 
          ...prev, 
          connected: false, 
          connecting: false, 
          error: 'è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ' 
        }));
      };

    } catch (err) {
      console.error('åˆå§‹åŒ–WebSocketå¤±è´¥:', err);
      setWsStatus(prev => ({ 
        ...prev, 
        connecting: false, 
        error: 'åˆå§‹åŒ–è¿æ¥å¤±è´¥' 
      }));
    }
  }, [examId, studentId, audioOnly, analysisEnabled, disabled, isAnalyzing, wsStatus.reconnectAttempts, onEmotionData, onAnalysisComplete, onTimelineEvent]);

  // é‡è¿æœºåˆ¶
  const scheduleReconnect = useCallback(() => {
    if (reconnectTimeoutRef.current) return;

    const delay = Math.pow(2, wsStatus.reconnectAttempts) * 1000; // æŒ‡æ•°é€€é¿
    reconnectTimeoutRef.current = setTimeout(() => {
      setWsStatus(prev => ({ ...prev, reconnectAttempts: prev.reconnectAttempts + 1 }));
      reconnectTimeoutRef.current = null;
      initWebSocket();
    }, delay);
  }, [wsStatus.reconnectAttempts, initWebSocket]);

  // è·å–åª’ä½“æµï¼ˆè§†é¢‘æˆ–ä»…éŸ³é¢‘ï¼‰
  const getMediaStream = useCallback(async () => {
    try {
      const constraints = audioOnly ? {
        video: false,
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 16000, // 16kHzé‡‡æ ·ç‡é€‚åˆè¯­éŸ³åˆ†æ
          channelCount: 1, // å•å£°é“
        },
      } : {
        video: {
          width: { ideal: 640 },
          height: { ideal: 480 },
          facingMode: 'user',
          frameRate: { ideal: 15 }, // é™ä½å¸§ç‡å‡å°‘å¸¦å®½
        },
        audio: false, // ä»…è§†é¢‘ç”¨äºæƒ…ç»ªåˆ†æ
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);

      if (audioOnly) {
        setAudioStream(stream);
        // åˆå§‹åŒ–éŸ³é¢‘åˆ†æå™¨
        initAudioAnalyser(stream);
      } else {
        setVideoStream(stream);
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          await videoRef.current.play();
        }
      }

      return stream;
    } catch (err) {
      console.error(`è·å–${audioOnly ? 'éŸ³é¢‘' : 'è§†é¢‘'}æµå¤±è´¥:`, err);
      throw err;
    }
  }, [audioOnly]);

  // åˆå§‹åŒ–éŸ³é¢‘åˆ†æå™¨
  const initAudioAnalyser = useCallback((stream: MediaStream) => {
    try {
      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
      
      // åˆ›å»ºåˆ†æå™¨èŠ‚ç‚¹
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 256;
      analyserRef.current.smoothingTimeConstant = 0.3;
      
      // è¿æ¥éŸ³é¢‘æº
      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(analyserRef.current);
      
      console.log('ğŸ¤ éŸ³é¢‘åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ');
    } catch (err) {
      console.error('åˆå§‹åŒ–éŸ³é¢‘åˆ†æå™¨å¤±è´¥:', err);
    }
  }, []);

  // è·å–éŸ³é¢‘çº§åˆ«
  const getAudioLevel = useCallback((): number => {
    if (!analyserRef.current) return 0;
    
    const bufferLength = analyserRef.current.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    analyserRef.current.getByteFrequencyData(dataArray);
    
    // è®¡ç®—å¹³å‡éŸ³é‡
    const sum = dataArray.reduce((a, b) => a + b);
    const average = sum / bufferLength;
    
    return Math.round((average / 255) * 100);
  }, []);

  // å‘é€éŸ³é¢‘æ•°æ®
  const sendAudioData = useCallback(() => {
    if (!wsRef.current || !analyserRef.current || wsStatus.connected === false) {
      return;
    }

    try {
      // è·å–é¢‘åŸŸæ•°æ®
      const bufferLength = analyserRef.current.frequencyBinCount;
      const frequencyData = new Uint8Array(bufferLength);
      analyserRef.current.getByteFrequencyData(frequencyData);
      
      // è·å–æ—¶åŸŸæ•°æ®
      const timeDomainData = new Uint8Array(bufferLength);
      analyserRef.current.getByteTimeDomainData(timeDomainData);
      
      // è®¡ç®—éŸ³é¢‘çº§åˆ«
      const level = getAudioLevel();
      setAudioLevel(level);
      
      // å‘é€éŸ³é¢‘æ•°æ®
      if (wsRef.current.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({
          type: 'audio_data',
          data: {
            frequency: Array.from(frequencyData),
            timeDomain: Array.from(timeDomainData),
            audioLevel: level,
          },
          timestamp: Date.now(),
          frameNumber: framesSent,
        }));
        
        setFramesSent(prev => prev + 1);
      }
    } catch (err) {
      console.error('å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥:', err);
    }
  }, [wsStatus.connected, framesSent, getAudioLevel]);

  // å‘é€è§†é¢‘å¸§
  const sendVideoFrame = useCallback(() => {
    if (!wsRef.current || !videoRef.current || !canvasRef.current || wsStatus.connected === false) {
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');

    if (!ctx || video.readyState !== video.HAVE_ENOUGH_DATA) {
      return;
    }

    // è®¾ç½®canvaså°ºå¯¸
    canvas.width = 320; // é™ä½åˆ†è¾¨ç‡å‡å°‘æ•°æ®é‡
    canvas.height = 240;

    // ç»˜åˆ¶è§†é¢‘å¸§
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    // è½¬æ¢ä¸ºbase64å›¾ç‰‡æ•°æ®
    try {
      const imageData = canvas.toDataURL('image/jpeg', 0.6); // é™ä½è´¨é‡å‡å°‘æ•°æ®é‡
      
      if (wsRef.current.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({
          type: 'video_frame',
          data: imageData,
          timestamp: Date.now(),
          frameNumber: framesSent,
        }));
        
        setFramesSent(prev => prev + 1);
      }
    } catch (err) {
      console.error('å‘é€è§†é¢‘å¸§å¤±è´¥:', err);
    }
  }, [wsStatus.connected, framesSent]);

  // å¼€å§‹æƒ…ç»ªåˆ†æ
  const startAnalysis = async () => {
    if (!analysisEnabled || disabled) return;

    try {
      setIsAnalyzing(true);
      onTimelineEvent?.('emotion_analysis_start', Date.now());

      // è·å–åª’ä½“æµï¼ˆè§†é¢‘æˆ–éŸ³é¢‘ï¼‰
      await getMediaStream();
      
      // åˆå§‹åŒ–WebSocketè¿æ¥
      await initWebSocket();

      // æ ¹æ®æ¨¡å¼è®¾ç½®æ•°æ®å‘é€é—´éš”
      if (audioOnly) {
        // éŸ³é¢‘æ¨¡å¼ï¼šæ¯100mså‘é€ä¸€æ¬¡æ•°æ®ï¼ˆ10Hzï¼‰
        intervalRef.current = setInterval(sendAudioData, 100);
      } else {
        // è§†é¢‘æ¨¡å¼ï¼šæ¯ç§’å‘é€2å¸§ç”¨äºåˆ†æ
        intervalRef.current = setInterval(sendVideoFrame, 500);
      }

    } catch (err) {
      console.error('å¼€å§‹æƒ…ç»ªåˆ†æå¤±è´¥:', err);
      setWsStatus(prev => ({ ...prev, error: 'å¯åŠ¨åˆ†æå¤±è´¥' }));
      setIsAnalyzing(false);
    }
  };

  // åœæ­¢æƒ…ç»ªåˆ†æ
  const stopAnalysis = () => {
    setIsAnalyzing(false);
    
    // å‘é€åœæ­¢æ¶ˆæ¯
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'stop_analysis',
        timestamp: Date.now(),
      }));
    }

    cleanup();
    onTimelineEvent?.('emotion_analysis_stop', Date.now());
  };

  // æ¸²æŸ“æƒ…ç»ªæ•°æ®
  const renderEmotionData = () => {
    if (!emotionData) return null;

    const emotions = Object.entries(emotionData.emotions).map(([emotion, value]) => ({
      name: emotion,
      value: Math.round(value * 100),
      color: {
        happiness: '#52c41a',
        sadness: '#1890ff',
        anger: '#ff4d4f',
        fear: '#fa8c16',
        surprise: '#722ed1',
        disgust: '#eb2f96',
      }[emotion] || '#666',
    }));

    return (
      <div style={{ marginTop: '12px' }}>
        <Text strong style={{ fontSize: '13px' }}>å®æ—¶æƒ…ç»ªåˆ†æ</Text>
        <div style={{ marginTop: '8px' }}>
          {emotions.map(({ name, value, color }) => (
            <div key={name} style={{ marginBottom: '4px' }}>
              <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
                <Text style={{ fontSize: '12px', textTransform: 'capitalize' }}>{name}</Text>
                <Text style={{ fontSize: '12px' }}>{value}%</Text>
              </div>
              <Progress 
                percent={value} 
                strokeColor={color}
                showInfo={false}
                size="small"
              />
            </div>
          ))}
        </div>
        <div style={{ marginTop: '8px', display: 'flex', justifyContent: 'space-between' }}>
          <Tag color="blue">ä¸“æ³¨åº¦: {Math.round(emotionData.engagement * 100)}%</Tag>
          <Tag color="orange">å‹åŠ›å€¼: {Math.round(emotionData.stress * 100)}%</Tag>
        </div>
      </div>
    );
  };

  if (disabled) {
    return (
      <Card size="small" style={{ opacity: 0.6 }}>
        <Text type="secondary">æƒ…ç»ªåˆ†æåŠŸèƒ½å·²ç¦ç”¨</Text>
      </Card>
    );
  }

  return (
    <Card
      size="small"
      style={{
        background: 'rgba(255, 255, 255, 0.9)',
        backdropFilter: 'blur(10px)',
        border: '1px solid rgba(0, 0, 0, 0.06)',
      }}
      title={
        <Space>
          {audioOnly ? <AudioOutlined /> : <EyeOutlined />}
          <Text strong>AI{audioOnly ? 'è¯­éŸ³' : 'æƒ…ç»ª'}åˆ†æ</Text>
          <Tag color={isAnalyzing ? 'processing' : wsStatus.connected ? 'success' : 'default'}>
            {isAnalyzing ? 'åˆ†æä¸­' : wsStatus.connected ? 'å·²è¿æ¥' : 'æœªè¿æ¥'}
          </Tag>
          {audioOnly && <Tag color="blue">ä»…éº¦å…‹é£</Tag>}
        </Space>
      }
    >
      <Space direction="vertical" style={{ width: '100%' }} size="small">
        {/* æ§åˆ¶é¢æ¿ */}
        <div style={{ display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
          <div style={{ display: 'flex', alignItems: 'center', gap: '8px' }}>
            <Text>å¯ç”¨åˆ†æ</Text>
            <Switch
              checked={analysisEnabled}
              onChange={setAnalysisEnabled}
              size="small"
              disabled={isAnalyzing}
            />
          </div>
          
          <Space>
            <Tooltip title={wsStatus.connected ? 'è¿æ¥æ­£å¸¸' : 'è¿æ¥æ–­å¼€'}>
              <Avatar 
                size="small"
                style={{ 
                  backgroundColor: wsStatus.connected ? '#52c41a' : '#ff4d4f' 
                }}
                icon={wsStatus.connected ? <LinkOutlined /> : <DisconnectOutlined />}
              />
            </Tooltip>
            
            {framesSent > 0 && (
              <Tag color="blue">å·²å‘é€ {framesSent} å¸§</Tag>
            )}
          </Space>
        </div>

        {/* é”™è¯¯æç¤º */}
        {wsStatus.error && (
          <Alert
            message={wsStatus.error}
            type="error"
            closable
            onClose={() => setWsStatus(prev => ({ ...prev, error: null }))}
            action={
              <Button 
                size="small" 
                onClick={initWebSocket}
                loading={wsStatus.connecting}
              >
                é‡è¯•
              </Button>
            }
          />
        )}

        {/* åª’ä½“æ˜¾ç¤ºåŒºåŸŸ */}
        {audioOnly ? (
          // éŸ³é¢‘æ¨¡å¼ï¼šæ˜¾ç¤ºéŸ³é¢‘çº§åˆ«
          <div style={{
            padding: '16px',
            background: '#f6f6f6',
            borderRadius: '8px',
            border: '1px solid #d9d9d9',
            textAlign: 'center'
          }}>
            <div style={{ marginBottom: '8px' }}>
              <Text type="secondary">ğŸ¤ éŸ³é¢‘è¾“å…¥</Text>
            </div>
            <div style={{
              width: '100%',
              height: '20px',
              background: '#e6e6e6',
              borderRadius: '10px',
              overflow: 'hidden',
              position: 'relative'
            }}>
              <div
                style={{
                  width: `${audioLevel}%`,
                  height: '100%',
                  background: audioLevel > 70 ? '#52c41a' : audioLevel > 30 ? '#faad14' : '#1890ff',
                  borderRadius: '10px',
                  transition: 'width 0.1s ease-out',
                }}
              />
            </div>
            <div style={{ marginTop: '4px', fontSize: '12px', color: '#666' }}>
              éŸ³é¢‘çº§åˆ«: {audioLevel}%
            </div>
          </div>
        ) : (
          // è§†é¢‘æ¨¡å¼ï¼šéšè—è§†é¢‘é¢„è§ˆ
          <div style={{ display: 'none' }}>
            <video ref={videoRef} />
            <canvas ref={canvasRef} />
          </div>
        )}

        {/* æ§åˆ¶æŒ‰é’® */}
        {analysisEnabled && (
          <Space>
            {!isAnalyzing ? (
              <Button
                type="primary"
                size="small"
                icon={audioOnly ? <AudioOutlined /> : <VideoCameraOutlined />}
                onClick={startAnalysis}
                loading={wsStatus.connecting}
              >
                å¼€å§‹{audioOnly ? 'è¯­éŸ³' : 'æƒ…ç»ª'}åˆ†æ
              </Button>
            ) : (
              <Button
                size="small"
                danger
                icon={<WarningOutlined />}
                onClick={stopAnalysis}
              >
                åœæ­¢åˆ†æ
              </Button>
            )}
            
            {wsStatus.reconnectAttempts > 0 && (
              <Tag color="warning">é‡è¿ {wsStatus.reconnectAttempts}/3</Tag>
            )}
          </Space>
        )}

        {/* æƒ…ç»ªæ•°æ®å±•ç¤º */}
        {isAnalyzing && emotionData && renderEmotionData()}

        {/* åˆ†æä¼šè¯ID */}
        {analysisSessionId.current && (
          <div style={{
            background: 'rgba(82, 196, 26, 0.1)',
            padding: '8px',
            borderRadius: '6px',
            border: '1px solid rgba(82, 196, 26, 0.2)',
            marginTop: '8px'
          }}>
            <div style={{ display: 'flex', alignItems: 'center', gap: '6px' }}>
              <CheckCircleOutlined style={{ color: '#52c41a' }} />
              <Text style={{ fontSize: '12px' }}>åˆ†æID: {analysisSessionId.current.slice(0, 8)}...</Text>
            </div>
          </div>
        )}
      </Space>
    </Card>
  );
};

export default EmotionAnalyzer;